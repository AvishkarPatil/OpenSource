import spacy

# Load the spaCy model
nlp = spacy.load("en_core_web_sm")

# Define your issues, languages, and topics for classification
issues = ["irrigation issues", "water scarcity", "crop failure", "weather conditions", "pest attack"]
languages = ["c++", "html", "java", "javascript", "python", "typescript"]
topics = ["android", "devops", "jupyter-notebook", "nlp", "open-source", "state-management", "ui-design", "webpack"]

# Combine all keywords (issues, languages, topics)
all_keywords = languages + topics

# Sample text to classify
text_blob = """
Its Just a Sample
Secure Innovation in Hidden Communication
JalWiKi: A Digital Platform for Water Conservation
Activity for Git, GitHub and GitLab Workshop by T-LUG
Sample Repo for Git and GitHub Workshop
API development of SweetSpot - Delivering Delight to Your Doorstep.
Telegram File to Link Fastest Bot, Its Generate Direct Links Quickly
### Open Source

This is Java File

# Neo4j + Vertex AI Codelab

A movie recommendation application that combines Neo4j's graph database capabilities with Google Cloud's Vertex AI for semantic search and natural language movie recommendations.

## üìù Blog Post

Check out the detailed explanation of this project in the blog post: [Building an Intelligent Movie Search with Neo4j and Vertex AI](https://sidagarwal04.medium.com/building-an-intelligent-movie-search-with-neo4j-and-vertex-ai-a38c75f79cf7)

## üöÄ Overview
This project demonstrates how to build an AI-powered movie recommendation engine using:

- **Neo4j**: Graph database for storing movie data and vector embeddings
- **Google Vertex AI**: For generating text embeddings and natural language processing
- **Gradio**: For creating a simple web interface

The system uses semantic search through vector embeddings generated by Vertex AI's text-embedding models to find movies based on natural language queries, and then leverages Gemini to produce conversational responses.
"""

# Process the text with spaCy
doc = nlp(text_blob)

# Check for keywords in the text and match them with the issues, languages, and topics
matched_keywords = [keyword for keyword in all_keywords if keyword.lower() in text_blob.lower()]

# Print matched keywords (issues, languages, topics)
print(f"Matched Keywords: {matched_keywords}")
